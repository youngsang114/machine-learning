{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 함수(Logistic Regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### odds = 일어나지 않을 확률에서의 일어날 확률\n",
    "    - 커질 수록, 일어날 확률이 높다\n",
    "    - ln(p/1-p) = w1x + x0\n",
    "    - p/1-p = e^(w1x+x0)\n",
    "    - p=1/1 + e^(-1*(w1x+x0))\n",
    "    - 시그 모이드함수에다가 회귀 값을 대입해준다면, 그에 맞는 확률값을 구할 수 있다\n",
    "    - 1/(1+e^-x) :  시그모이드 함수\n",
    "    - C는 1/alpha이므로 작을 수록 규제가 크다 (SNM에서는 C값이 클수록 큐제가 크다)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.linear_model.LogisticRegression\n",
    "* class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "* prarmeters\n",
    "    - penalty :{‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’\n",
    "    - C :Inverse of regularization strength , float, default=1.0\n",
    "    - max_iter : 최대 몇번 학습 할건지(에포크), int, default=100\n",
    "    - multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "        - 'auto' : 알아서 계산해준다\n",
    "        - ‘ovr’: 이진분류\n",
    "        - ‘multinomial’는 solver=’liblinear’일때 불가능.\n",
    "        - ‘auto’ ---> ‘ovr’ : 데이터가 이진 분류 혹은  solver=’liblinear’일때\n",
    "        - ‘auto’ ---> ‘multinomial’: 데이터가 다중 분류 혹은 solver가 나머지거 일때\n",
    "    \n",
    "    - solver : {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "        - For small datasets, ‘liblinear’ is a good choice\n",
    "        - ‘sag’ and ‘saga’ are faster for large ones;\n",
    "        - \n",
    "* multi- classifier : 레이블이 여러개 값 일때\n",
    "    - 시그모이드에 대입하는 것이 아니라, softmax function에 대입해야 한다\n",
    "    - 엔트로피를 카테고리컬 엔트로피를 구해준다(one-hot encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning메시지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cancer= load_breast_cancer()\n",
    "\n",
    "scaler= StandardScaler()\n",
    "data_scaled= scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_scaled,cancer.target,test_size=0.3,random_state=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.977\n",
      "roc_auc:0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf= LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred= lr_clf.predict(X_test)\n",
    "\n",
    "print(f'accuracy:{accuracy_score(y_test,lr_pred):.3f}')\n",
    "print(f'roc_auc:{roc_auc_score(y_test,lr_pred):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:{'C': 1, 'penalty': 'l2'}, 최적 평균 정확도:0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params={'penalty':['l2','l1'],\n",
    "        'C':[0.01,0.1,1,5,10]}\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy',cv=3)\n",
    "grid_clf.fit(data_scaled,cancer.target)\n",
    "\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_,grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.357943</td>\n",
       "      <td>2.837570e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.464811</td>\n",
       "      <td>0.363490</td>\n",
       "      <td>3.469014e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>7.354107e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.026120</td>\n",
       "      <td>1.614249e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024095</td>\n",
       "      <td>0.161514</td>\n",
       "      <td>1.207245e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.968179</td>\n",
       "      <td>0.730649</td>\n",
       "      <td>5.657152e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.995757</td>\n",
       "      <td>0.950313</td>\n",
       "      <td>9.899404e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1             2\n",
       "count  45.000000  45.000000  4.500000e+01\n",
       "mean    0.358300   0.357943  2.837570e-01\n",
       "std     0.464811   0.363490  3.469014e-01\n",
       "min     0.000026   0.004243  7.354107e-08\n",
       "25%     0.002583   0.026120  1.614249e-06\n",
       "50%     0.024095   0.161514  1.207245e-01\n",
       "75%     0.968179   0.730649  5.657152e-01\n",
       "max     0.995757   0.950313  9.899404e-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "scaler= StandardScaler()\n",
    "iris_scaled= scaler.fit_transform(iris.data)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_scaled,iris.target,test_size=0.3,random_state=0 )\n",
    "\n",
    "lg_clf= LogisticRegression()\n",
    "lg_clf.fit(X_train,y_train)\n",
    "lg_pred= lg_clf.predict_proba(X_test)\n",
    "pd.DataFrame(lg_pred).describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.335794</td>\n",
       "      <td>0.356153</td>\n",
       "      <td>0.308052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.425608</td>\n",
       "      <td>0.268351</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.018802</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005230</td>\n",
       "      <td>0.106595</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.043824</td>\n",
       "      <td>0.277675</td>\n",
       "      <td>0.236031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.881048</td>\n",
       "      <td>0.542622</td>\n",
       "      <td>0.536531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.981176</td>\n",
       "      <td>0.917569</td>\n",
       "      <td>0.903337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2\n",
       "count  45.000000  45.000000  45.000000\n",
       "mean    0.335794   0.356153   0.308052\n",
       "std     0.425608   0.268351   0.304600\n",
       "min     0.000239   0.018802   0.000019\n",
       "25%     0.005230   0.106595   0.000069\n",
       "50%     0.043824   0.277675   0.236031\n",
       "75%     0.881048   0.542622   0.536531\n",
       "max     0.981176   0.917569   0.903337"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_clf= LogisticRegression(multi_class='ovr')\n",
    "lg_clf.fit(X_train,y_train)\n",
    "lg_pred= lg_clf.predict_proba(X_test)\n",
    "lg_pred= lg_clf.predict_proba(X_test)\n",
    "pd.DataFrame(lg_pred).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 folds 의 개별 Negative MSE scores :  [ -8.01 -14.6  -20.97 -47.   -21.61]\n",
      " 5 folds 의 개별 RMSE scores :  [2.83 3.82 4.58 6.86 4.65]\n",
      " 5 folds 의 평균 RMSE : 4.547 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# boston 데이터셋 로드\n",
    "bostondf = pd.read_csv('../datasets/Boston.csv', index_col=0)\n",
    "\n",
    "# boston dataset의 target array는 주택 가격. price 컬럼으로 설정\n",
    "bostondf.rename(columns = {'medv':'price'},inplace=True)\n",
    "\n",
    "y_target = bostondf['Price']\n",
    "X_data = bostondf.drop(['Price'],axis=1,inplace=False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring='neg_mean_squared_error', cv = 5)\n",
    "rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(' 5 folds 의 개별 Negative MSE scores : ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores, 2))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv =5)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print('##### {0} #####'.format(model))\n",
    "    print(\"avg socres : \", np.round(avg_rmse, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "\n",
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행\n",
    "models = [dt_reg, rf_reg, gb_reg]\n",
    "for model in models:\n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# 앞 예제에서 만들어진 X_data, y_target 데이터 셋을 적용하여 학습한다.\n",
    "rf_reg.fit(X_data, y_target)\n",
    "\n",
    "feature_series = pd.Series(data=rf_reg.feature_importances_, index=X_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y=feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "bostondf_sample = bostondf[['rm', 'price']]\n",
    "bostondf_sample = bostondf_sample.sample(n=100, random_state=0)\n",
    "print(bostondf_sample.shape)\n",
    "plt.figure()\n",
    "plt.scatter(bostondf_sample.rm, bostondf_sample.price, c='darkorange')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 선형 회귀와 결정 트리 기반의 Regressor 생성. DecisionTreeRegressor의 max_depth는 각각 2, 7\n",
    "lr_reg = LinearRegression()\n",
    "rf_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "rf_reg7 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "# 실제 예측을 적용할 테스트용 데이터 셋을 4.5~8.5까지 100개 데이터 셋 생성.\n",
    "X_test = np.arange(4.5, 8.5, 0.04).reshape(-1,1)\n",
    "\n",
    "# 보스턴 주택가격 데이터에서 시각화를 위해 피처는 rm만, 그리고 결정 데이터인 price 추출\n",
    "X_feature = bostondf_sample['rm'].values.reshape(-1,1)\n",
    "y_target = bostondf_sample['price'].values.reshape(-1,1)\n",
    "\n",
    "# 학습과 예측 수행\n",
    "lr_reg.fit(X_feature, y_target)\n",
    "rf_reg2.fit(X_feature, y_target)\n",
    "rf_reg7.fit(X_feature, y_target)\n",
    "\n",
    "pred_lr = lr_reg.predict(X_test)\n",
    "pred_rf2 = rf_reg2.predict(X_test)\n",
    "pred_rf7 = rf_reg7.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(14,4), ncols=3)\n",
    "\n",
    "# X축값을 4.5~8.5로 변환하며 입력했을 때, 선형 회귀와 결정 트리 회귀 예측 선 시각화\n",
    "# 선형 회귀로 학습된 모델 회귀 예측선\n",
    "ax1.set_title('Linear Regression')\n",
    "ax1.scatter(bostondf_sample.rm, bostondf_sample.price, c='darkorange')\n",
    "ax1.plot(X_test, pred_lr, label='linear', linewidth=2)\n",
    "\n",
    "# DecisionTreeRegressor의 max_depth를 2로 했을 때 회귀 예측선\n",
    "ax2.set_title('Decision Tree Regression: \\n max_depth=2')\n",
    "ax2.scatter(bostondf_sample.rm, bostondf_sample.price, c='darkorange')\n",
    "ax2.plot(X_test, pred_rf2, label='max_depth:2', linewidth=2)\n",
    "\n",
    "# DecisionTreeRegressor의 max_depth를 7로 했을 때 회귀 예측선\n",
    "ax3.set_title('Decision Tree Regression: \\n max_depth=7')\n",
    "ax3.scatter(bostondf_sample.rm, bostondf_sample.price, c='darkorange')\n",
    "ax3.plot(X_test, pred_rf7, label='max_depth:2', linewidth=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
