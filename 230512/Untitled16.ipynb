{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- adaboost: 약한 분류기에 weight를 주는 것\n",
        "- gbm(gradient boost machine) : 오류(rss)를 줄여나가는 경사 하강\n",
        "단점: 시간 오래 걸림\n",
        "좀 더 빨리한 게 lightgbm\n",
        "-lightgbm: 차이를 최대한 줄여주는 것\n",
        "단점: 과대적합 문제, 시간 오래 걸리는 문제\n",
        "-> 개선 위해 규제를 줌. (cost function 최소화하는걸 규제)중간에 멈추게 함: xgboost 빠르고 효과적\n",
        "\n",
        "시계열 데이터에 효과적"
      ],
      "metadata": {
        "id": "HYj-Xb8Mz4qS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FQbaCOwop_0Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import time\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_name_df = pd.read_csv(\"/content/drive/MyDrive/UCI HAR Dataset/features.txt\", \\\n",
        "    sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
        "\n",
        "feature_name = feature_name_df.iloc[:,1].values.tolist()\n",
        "\n",
        "def get_new_feature_name_df(old_feature_name_df):\n",
        "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
        "                                  columns=['dup_cnt'])\n",
        "    feature_dup_df = feature_dup_df.reset_index()\n",
        "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
        "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'-'+str(x[1])\n",
        "                                                                                                            if x[1] > 0 else x[0], axis=1)\n",
        "    \n",
        "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
        "    return new_feature_name_df\n",
        "\n",
        "def get_human_dataset():\n",
        "    \n",
        "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백문자를 sep으로 할당\n",
        "    feature_name_df = pd.read_csv('/content/drive/MyDrive/UCI HAR Dataset/features.txt', sep='\\s+',\n",
        "                                                     header=None, names=['column_index', 'column_name'])\n",
        "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame 생성\n",
        "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
        "\n",
        "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 반환\n",
        "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
        "    \n",
        "    # 학습 피처 데이터세트와 테스트 피처 데이터를 데이터프레임으로 로딩\n",
        "    # 컬럼명은 feature_name 적용\n",
        "    X_train = pd.read_csv('/content/drive/MyDrive/UCI HAR Dataset/train/X_train.txt', sep='\\s+', names=feature_name)\n",
        "    X_test = pd.read_csv('/content/drive/MyDrive/UCI HAR Dataset/test/X_test.txt', sep='\\s+', names=feature_name)\n",
        "    \n",
        "    # 학습 레이블과 테스트 레이블 데이터를 데이터 프레임으로 로딩, 컬럼명은 action으로 부여\n",
        "    y_train = pd.read_csv('/content/drive/MyDrive/UCI HAR Dataset/train/y_train.txt', sep='\\s+', header=None, names=['action'])\n",
        "    y_test = pd.read_csv('/content/drive/MyDrive/UCI HAR Dataset/test/y_test.txt', sep='\\s+', header=None, names=['action'])\n",
        "    \n",
        "    # 로드된 학습/테스트용 데이터프레임을 모두 반환\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_human_dataset()"
      ],
      "metadata": {
        "id": "jpsa9ZqCqFwb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "start_time = time.time()\n",
        "gb_clf = GradientBoostingClassifier(random_state=0)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "gb_pred = gb_clf.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "\n",
        "print(gb_pred)\n",
        "print(time.time()-start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZIfyJAJqJgY",
        "outputId": "8ed256e9-7e69-4313-84c8-fdc81404117e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 5 5 ... 2 2 2]\n",
            "1043.584258556366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gb_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOnQu-U4yoco",
        "outputId": "e4153d85-7228-4615-a21b-95d5300dbf5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9385816084153377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziEBxu2KqRNC",
        "outputId": "ee66b0d9-9713-49eb-9bbd-76f8457003ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb ## XGBoost 불러오기\n",
        "from xgboost import plot_importance ## Feature Importance를 불러오기 위함\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features = dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "cancer_df = pd.DataFrame(data=X_features, columns = dataset.feature_names)\n",
        "cancer_df['target'] = y_label\n",
        "cancer_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "8uZkKM5Bttz8",
        "outputId": "d8b11447-e991-454d-8fe1-b969d5ac5a44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38           122.8     1001.0          0.11840   \n",
              "1        20.57         17.77           132.9     1326.0          0.08474   \n",
              "2        19.69         21.25           130.0     1203.0          0.10960   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "\n",
              "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                 0.07871  ...          17.33            184.6      2019.0   \n",
              "1                 0.05667  ...          23.41            158.8      1956.0   \n",
              "2                 0.05999  ...          25.53            152.5      1709.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  target  \n",
              "0          0.4601                  0.11890       0  \n",
              "1          0.2750                  0.08902       0  \n",
              "2          0.3613                  0.08758       0  \n",
              "\n",
              "[3 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6702cc8c-3d4c-44bf-a5bf-013212c0f416\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6702cc8c-3d4c-44bf-a5bf-013212c0f416')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6702cc8c-3d4c-44bf-a5bf-013212c0f416 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6702cc8c-3d4c-44bf-a5bf-013212c0f416');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5wMkO1NzoLE",
        "outputId": "419cbac0-63cf-4861-bfca-a0734050b6b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30) (114, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_clf_eval(y_test, y_pred):\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    F1 = f1_score(y_test, y_pred)\n",
        "    AUC = roc_auc_score(y_test, y_pred)\n",
        "    print('오차행렬:\\n', confusion)\n",
        "    print('\\n정확도: {:.4f}'.format(accuracy))\n",
        "    print('정밀도: {:.4f}'.format(precision))\n",
        "    print('재현율: {:.4f}'.format(recall))\n",
        "    print('F1: {:.4f}'.format(F1))\n",
        "    print('AUC: {:.4f}'.format(AUC))"
      ],
      "metadata": {
        "id": "fdDM3obKt5F6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain = xgb.DMatrix(data=X_train, label = y_train)\n",
        "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
        "\n",
        "params = {'max_depth' : 3,\n",
        "         'eta' : 0.1, \n",
        "         'objective' : 'binary:logistic',\n",
        "         'eval_metric' : 'logloss',\n",
        "         'early_stoppings' : 100 }\n",
        "\n",
        "num_rounds = 400\n",
        "\n",
        "# train 데이터 세트는 'train', evaluation(test) 데이터 세트는 'eval' 로 명기\n",
        "wlist = [(dtrain, 'train'), (dtest,'eval')]\n",
        "# 하이퍼 파라미터와 early stopping 파라미터를 train() 함수의 파라미터로 전달\n",
        "xgb_model = xgb.train(params = params, dtrain=dtrain, num_boost_round=num_rounds, evals=wlist)\n",
        "\n",
        "pred_probs = xgb_model.predict(dtest)\n",
        "preds = [ 1 if x > 0.5 else 0 for x in pred_probs]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQwCk7Hmt0KZ",
        "outputId": "b435093b-f99e-4f1b-a370-29e917212712"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:13:33] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"early_stoppings\" } are not used.\n",
            "\n",
            "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
            "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
            "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
            "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
            "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
            "[5]\ttrain-logloss:0.35415\teval-logloss:0.37498\n",
            "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
            "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
            "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
            "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
            "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
            "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
            "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
            "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
            "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
            "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
            "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
            "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
            "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
            "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
            "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
            "[21]\ttrain-logloss:0.10297\teval-logloss:0.15472\n",
            "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
            "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
            "[24]\ttrain-logloss:0.08634\teval-logloss:0.13634\n",
            "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
            "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
            "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
            "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
            "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
            "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
            "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
            "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
            "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
            "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
            "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
            "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
            "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
            "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
            "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
            "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
            "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
            "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
            "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
            "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
            "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
            "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
            "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
            "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
            "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
            "[50]\ttrain-logloss:0.02854\teval-logloss:0.09005\n",
            "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
            "[52]\ttrain-logloss:0.02656\teval-logloss:0.08958\n",
            "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
            "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
            "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
            "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
            "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
            "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
            "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
            "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
            "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
            "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
            "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
            "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
            "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
            "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
            "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
            "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
            "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
            "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
            "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
            "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
            "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
            "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
            "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
            "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
            "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
            "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
            "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
            "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
            "[81]\ttrain-logloss:0.01400\teval-logloss:0.08741\n",
            "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
            "[83]\ttrain-logloss:0.01357\teval-logloss:0.08857\n",
            "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
            "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
            "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
            "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
            "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
            "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
            "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
            "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
            "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
            "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
            "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
            "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
            "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
            "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
            "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
            "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
            "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
            "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
            "[102]\ttrain-logloss:0.01075\teval-logloss:0.08629\n",
            "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
            "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
            "[105]\ttrain-logloss:0.01040\teval-logloss:0.08677\n",
            "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
            "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
            "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
            "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
            "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
            "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
            "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
            "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
            "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
            "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
            "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
            "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
            "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
            "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
            "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
            "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
            "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
            "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
            "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
            "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
            "[126]\ttrain-logloss:0.00871\teval-logloss:0.08827\n",
            "[127]\ttrain-logloss:0.00865\teval-logloss:0.08831\n",
            "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
            "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
            "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
            "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
            "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
            "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
            "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
            "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
            "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
            "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
            "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
            "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
            "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
            "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
            "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
            "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
            "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
            "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
            "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
            "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
            "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
            "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
            "[150]\ttrain-logloss:0.00757\teval-logloss:0.08911\n",
            "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
            "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
            "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
            "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
            "[155]\ttrain-logloss:0.00739\teval-logloss:0.08855\n",
            "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
            "[157]\ttrain-logloss:0.00735\teval-logloss:0.08855\n",
            "[158]\ttrain-logloss:0.00732\teval-logloss:0.08827\n",
            "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
            "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
            "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
            "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n",
            "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
            "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
            "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
            "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
            "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
            "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
            "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n",
            "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
            "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
            "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
            "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
            "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
            "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
            "[176]\ttrain-logloss:0.00697\teval-logloss:0.08695\n",
            "[177]\ttrain-logloss:0.00695\teval-logloss:0.08705\n",
            "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
            "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
            "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
            "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
            "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
            "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
            "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
            "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
            "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
            "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
            "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
            "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
            "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
            "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
            "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
            "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
            "[194]\ttrain-logloss:0.00667\teval-logloss:0.08591\n",
            "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
            "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
            "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
            "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
            "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
            "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
            "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
            "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
            "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
            "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
            "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
            "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
            "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
            "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
            "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
            "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
            "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
            "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
            "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
            "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
            "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
            "[216]\ttrain-logloss:0.00635\teval-logloss:0.08584\n",
            "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
            "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
            "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
            "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
            "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
            "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
            "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
            "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
            "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
            "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
            "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
            "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
            "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
            "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
            "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
            "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
            "[233]\ttrain-logloss:0.00614\teval-logloss:0.08611\n",
            "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
            "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
            "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
            "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
            "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
            "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
            "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
            "[241]\ttrain-logloss:0.00605\teval-logloss:0.08620\n",
            "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
            "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
            "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
            "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
            "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
            "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
            "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
            "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
            "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
            "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
            "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
            "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
            "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
            "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
            "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
            "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
            "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
            "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
            "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
            "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
            "[262]\ttrain-logloss:0.00584\teval-logloss:0.08645\n",
            "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
            "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
            "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
            "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
            "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
            "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
            "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
            "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
            "[271]\ttrain-logloss:0.00576\teval-logloss:0.08674\n",
            "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
            "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
            "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
            "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
            "[276]\ttrain-logloss:0.00571\teval-logloss:0.08635\n",
            "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
            "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
            "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
            "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
            "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
            "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
            "[283]\ttrain-logloss:0.00565\teval-logloss:0.08636\n",
            "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
            "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
            "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
            "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
            "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
            "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
            "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
            "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
            "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
            "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
            "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
            "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
            "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
            "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
            "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
            "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
            "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
            "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
            "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
            "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
            "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
            "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
            "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
            "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
            "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
            "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
            "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n",
            "[311]\ttrain-logloss:0.00545\teval-logloss:0.08595\n",
            "[312]\ttrain-logloss:0.00544\teval-logloss:0.08603\n",
            "[313]\ttrain-logloss:0.00544\teval-logloss:0.08611\n",
            "[314]\ttrain-logloss:0.00543\teval-logloss:0.08599\n",
            "[315]\ttrain-logloss:0.00542\teval-logloss:0.08590\n",
            "[316]\ttrain-logloss:0.00542\teval-logloss:0.08595\n",
            "[317]\ttrain-logloss:0.00541\teval-logloss:0.08598\n",
            "[318]\ttrain-logloss:0.00540\teval-logloss:0.08600\n",
            "[319]\ttrain-logloss:0.00540\teval-logloss:0.08588\n",
            "[320]\ttrain-logloss:0.00539\teval-logloss:0.08597\n",
            "[321]\ttrain-logloss:0.00539\teval-logloss:0.08605\n",
            "[322]\ttrain-logloss:0.00538\teval-logloss:0.08609\n",
            "[323]\ttrain-logloss:0.00537\teval-logloss:0.08598\n",
            "[324]\ttrain-logloss:0.00537\teval-logloss:0.08598\n",
            "[325]\ttrain-logloss:0.00536\teval-logloss:0.08590\n",
            "[326]\ttrain-logloss:0.00535\teval-logloss:0.08578\n",
            "[327]\ttrain-logloss:0.00535\teval-logloss:0.08586\n",
            "[328]\ttrain-logloss:0.00534\teval-logloss:0.08594\n",
            "[329]\ttrain-logloss:0.00534\teval-logloss:0.08582\n",
            "[330]\ttrain-logloss:0.00533\teval-logloss:0.08587\n",
            "[331]\ttrain-logloss:0.00532\teval-logloss:0.08589\n",
            "[332]\ttrain-logloss:0.00532\teval-logloss:0.08592\n",
            "[333]\ttrain-logloss:0.00531\teval-logloss:0.08584\n",
            "[334]\ttrain-logloss:0.00531\teval-logloss:0.08574\n",
            "[335]\ttrain-logloss:0.00530\teval-logloss:0.08582\n",
            "[336]\ttrain-logloss:0.00529\teval-logloss:0.08589\n",
            "[337]\ttrain-logloss:0.00529\teval-logloss:0.08594\n",
            "[338]\ttrain-logloss:0.00528\teval-logloss:0.08583\n",
            "[339]\ttrain-logloss:0.00528\teval-logloss:0.08591\n",
            "[340]\ttrain-logloss:0.00527\teval-logloss:0.08583\n",
            "[341]\ttrain-logloss:0.00527\teval-logloss:0.08573\n",
            "[342]\ttrain-logloss:0.00526\teval-logloss:0.08568\n",
            "[343]\ttrain-logloss:0.00525\teval-logloss:0.08572\n",
            "[344]\ttrain-logloss:0.00525\teval-logloss:0.08580\n",
            "[345]\ttrain-logloss:0.00524\teval-logloss:0.08582\n",
            "[346]\ttrain-logloss:0.00524\teval-logloss:0.08572\n",
            "[347]\ttrain-logloss:0.00523\teval-logloss:0.08579\n",
            "[348]\ttrain-logloss:0.00523\teval-logloss:0.08584\n",
            "[349]\ttrain-logloss:0.00522\teval-logloss:0.08573\n",
            "[350]\ttrain-logloss:0.00522\teval-logloss:0.08566\n",
            "[351]\ttrain-logloss:0.00521\teval-logloss:0.08573\n",
            "[352]\ttrain-logloss:0.00521\teval-logloss:0.08581\n",
            "[353]\ttrain-logloss:0.00520\teval-logloss:0.08571\n",
            "[354]\ttrain-logloss:0.00519\teval-logloss:0.08566\n",
            "[355]\ttrain-logloss:0.00519\teval-logloss:0.08570\n",
            "[356]\ttrain-logloss:0.00518\teval-logloss:0.08563\n",
            "[357]\ttrain-logloss:0.00518\teval-logloss:0.08553\n",
            "[358]\ttrain-logloss:0.00517\teval-logloss:0.08560\n",
            "[359]\ttrain-logloss:0.00517\teval-logloss:0.08568\n",
            "[360]\ttrain-logloss:0.00516\teval-logloss:0.08558\n",
            "[361]\ttrain-logloss:0.00516\teval-logloss:0.08560\n",
            "[362]\ttrain-logloss:0.00515\teval-logloss:0.08564\n",
            "[363]\ttrain-logloss:0.00515\teval-logloss:0.08571\n",
            "[364]\ttrain-logloss:0.00514\teval-logloss:0.08579\n",
            "[365]\ttrain-logloss:0.00514\teval-logloss:0.08569\n",
            "[366]\ttrain-logloss:0.00513\teval-logloss:0.08573\n",
            "[367]\ttrain-logloss:0.00513\teval-logloss:0.08568\n",
            "[368]\ttrain-logloss:0.00512\teval-logloss:0.08559\n",
            "[369]\ttrain-logloss:0.00512\teval-logloss:0.08552\n",
            "[370]\ttrain-logloss:0.00511\teval-logloss:0.08559\n",
            "[371]\ttrain-logloss:0.00511\teval-logloss:0.08550\n",
            "[372]\ttrain-logloss:0.00511\teval-logloss:0.08556\n",
            "[373]\ttrain-logloss:0.00510\teval-logloss:0.08560\n",
            "[374]\ttrain-logloss:0.00510\teval-logloss:0.08563\n",
            "[375]\ttrain-logloss:0.00509\teval-logloss:0.08553\n",
            "[376]\ttrain-logloss:0.00509\teval-logloss:0.08561\n",
            "[377]\ttrain-logloss:0.00508\teval-logloss:0.08567\n",
            "[378]\ttrain-logloss:0.00508\teval-logloss:0.08571\n",
            "[379]\ttrain-logloss:0.00507\teval-logloss:0.08562\n",
            "[380]\ttrain-logloss:0.00507\teval-logloss:0.08558\n",
            "[381]\ttrain-logloss:0.00506\teval-logloss:0.08562\n",
            "[382]\ttrain-logloss:0.00506\teval-logloss:0.08564\n",
            "[383]\ttrain-logloss:0.00506\teval-logloss:0.08555\n",
            "[384]\ttrain-logloss:0.00505\teval-logloss:0.08562\n",
            "[385]\ttrain-logloss:0.00505\teval-logloss:0.08562\n",
            "[386]\ttrain-logloss:0.00504\teval-logloss:0.08555\n",
            "[387]\ttrain-logloss:0.00504\teval-logloss:0.08546\n",
            "[388]\ttrain-logloss:0.00503\teval-logloss:0.08550\n",
            "[389]\ttrain-logloss:0.00503\teval-logloss:0.08546\n",
            "[390]\ttrain-logloss:0.00503\teval-logloss:0.08532\n",
            "[391]\ttrain-logloss:0.00502\teval-logloss:0.08539\n",
            "[392]\ttrain-logloss:0.00502\teval-logloss:0.08530\n",
            "[393]\ttrain-logloss:0.00501\teval-logloss:0.08537\n",
            "[394]\ttrain-logloss:0.00501\teval-logloss:0.08530\n",
            "[395]\ttrain-logloss:0.00500\teval-logloss:0.08537\n",
            "[396]\ttrain-logloss:0.00500\teval-logloss:0.08528\n",
            "[397]\ttrain-logloss:0.00500\teval-logloss:0.08532\n",
            "[398]\ttrain-logloss:0.00499\teval-logloss:0.08528\n",
            "[399]\ttrain-logloss:0.00499\teval-logloss:0.08520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_clf_eval(y_test, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLr7lEWHt5tn",
        "outputId": "44007421-9a59-4161-b460-fc05d56a8260"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차행렬:\n",
            " [[35  2]\n",
            " [ 1 76]]\n",
            "\n",
            "정확도: 0.9737\n",
            "정밀도: 0.9744\n",
            "재현율: 0.9870\n",
            "F1: 0.9806\n",
            "AUC: 0.9665\n"
          ]
        }
      ]
    }
  ]
}